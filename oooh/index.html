<!DOCTYPE html>
<html lang="en-US">
<head>
    <title>Oooh Client Architecture</title>
    <style>

        :root {
            --main-text-color: #F5F7FA;
            --secondary-text-color: #E4E7EB;
            --link-color: #FEFF00;
        }

        body {
            max-width: 80ch;
            margin: auto;
            background-image: url("background.jpg");
            background-repeat: repeat-x;
            background-color: #DA1CB9;
            color: var(--main-text-color);
            padding: 10px;
        }

        h2 {
            border-bottom: 1px solid;
        }

        h3 {
            color: var(--secondary-text-color);
        }

        img {
            max-width: 100%;
            object-fit: contain;
        }

        a {
            text-decoration: none;
            color: var(--link-color);
        }

        ul {
            list-style-type: none;
            padding-left: 1em;
        }

        figure {
            border: 1px var(--secondary-text-color) solid;
            padding: 1em 1em 0 1em;
            width: fit-content;
            margin: auto;
        }

        figcaption {
            text-align: center;
            color: var(--secondary-text-color);
        }

        li:before {
            content: "» ";
        }

        header {
            text-align: center;
        }

        .warning::before {
            content: "⚠️ Warning";
            display: block;
        }

        .warning {
            background-color: rgba(255, 42, 81, 0.3);
            border: none;
            border-left: 2px solid #ff2a51;
            border-radius: 0.25rem;
        }

        dialog {
            position: static;
            color: var(--main-text-color);
        }

        .column {
            box-sizing: border-box;
            float: left;
            width: 50%;
            padding-right: 1em;
        }

        .row:after {
            content: "";
            display: table;
            clear: both;
        }

        @media screen and (max-width: 80ch) {
            .column {
                width: 100%;
            }
        }

        @media print {
            :root {
                --main-text-color: black;
                --secondary-text-color: black;
                --link-color: black;
            }

            body {
                background-color: white;
                background-image: none;
            }

            img {
                max-height: 300px;
            }
        }
    </style>
</head>
<body>
<header>
    <h1>Oooh Client Architecture</h1>
    <i>History, components and design of the Oooh app</i>
    <p>
        by <a href="https://www.linkedin.com/in/allan--bush/">Allan Bush</a> VP of Engineering
    </p>
</header>
<h2>Starting Up</h2>
<p>
    Oooh was founded in 2019. Its mission was to create a social platform that encouraged safe, positive engagement for
    its community of users.
</p>
<p>
    Over the course of five and a half years, the product underwent many iterations and pivots. This document provides
    some history into the major pivots, app component highlights, and the architectural decisions to support the product
    goals at different stages.
</p>
<h3>Why Unity?</h3>
<p>
    This is a question that often comes up, as later iterations of Oooh are not the type of app traditionally created
    with Unity.
</p>
<p>
    Oooh was founded by a team of engineers who previously worked on Disney's Club Penguin mobile app, created with
    Unity. Additionally, the first iteration of the app was based on combining games and videos in one app.
</p>
<p>
    With the goal of creating a single codebase app capable of running on iOS and Android, a cross-platform framework of
    some type was required. Given the internal expertise, the need to create many small games, and the quick prototyping
    ability of Unity, Unity was chosen as the best option to create the app.
</p>
<h3>CI/CD</h3>
<p>
    The goal of continuous integration for the mobile client was to:
</p>
<ul>
    <li>Successfully run unit tests before GitHub pull requests could be merged into protected branches</li>
    <li>Generate an iOS and Android build for every commit to a protected branch</li>
    <li>Allow team members to easily install any CI generated build</li>
</ul>
<p>
    Given the requirement to create iOS builds, a CI system running OSX was required. At the time, there were few cloud
    providers with this option. Additionally, we didn't have a dedicated dev ops / build engineer — and never did — so
    something with a simple setup and without the need for continuous maintenance was required. Unity Cloud Build (now
    Unity Build Automation) was our chosen solution, and the following setup was created:
</p>
<ul>
    <li>PR opened → GitHub webhook → AWS Lambda function → Create UCB build configuration from a template</li>
    <li>Commit to a PR branch → Run Unity Unit Tests → UCB webhook → AWS Lambda function → Set GitHub commit status</li>
    <li>After a PR review and a successful run of the Unit tests, allow the branch to be merged</li>
    <li>Commit to a protected branch (release/* | main) → Build Android + iOS builds in UCB</li>
    <li>iOS builds signed using fastlane + match</li>
    <li>Successful iOS build added to TestFlight, release candidate Android builds uploaded to Google Play Console</li>
    <li>Debug symbols uploaded to Crashlytics</li>
</ul>
<dialog open class="warning">
    At the time of choosing UCB, it was a flat rate of $30 a month. It's now pay as you go and was costing ~$1000 a month
    for a team of < 10 engineers. The service is also:
    <ul>
        <li>very slow: builds are 5x slower than local builds</li>
        <li>unreliable: ~5% of builds fail due to random network issues or build node failures</li>
        <li>outdated: Xcode 15.3 still isn't available — 7 months after its release and counting</li>
    </ul>
    If I was picking a CI/CD system for a Unity project today, I would look elsewhere.
</dialog>

<h2>Videos and Games</h2>
<p>
    The first iteration of Oooh was a platform of videos and games for young children. The primary focus was to encourage
    game play as additional interaction instead of passively watching videos for long periods of time.
</p>
<figure>
    <img src="MileStone0.webp" alt="Video and Games version screenshot">
    <figcaption>Early App Screenshot</figcaption>
</figure>
<h3>Module Engine</h3>
<p>
    Although we were able to create first-party casual games relatively quickly, if Oooh was going to be a platform, we
    needed a way for third-party developers to create their own games. Evaluating the options for runtime delivery of new
    games, we decided to support running HTML games inside our app as it was the simplest and most flexible option.
</p>
<p>
    Not wanting to limit HTML content to games, we coined the term <i>module</i> to represent an interactive experience.
    And created the <i>Module Engine</i>, which allowed a module running either in Unity or in a webview to
    interact with the rest of the app.
</p>
<p>
    The Module Engine controls the flow of handing-off UI control from the app to the module and vice versa. It enables
    communication between C# code in the app and JavaScript in the module. This allows the content running within a
    webview inside an app to do many things which are normally limited to native apps.
</p>
<figure>
    <img src="ModuleEngine.webp" alt="Module Engine Architecture diagram">
    <figcaption>Module Engine Architecture</figcaption>
</figure>
<p>
    In our app, modules are versioned so that user replays always run against the same version of the code, and
    third-party developers don't need to worry about version incompatibilities in their data. They communicate with the
    app via the <a href="https://module.oooh.io/api/o3h.js">o3h.js</a> library loaded at runtime.
</p>
<p>
    The o3h.js library is written in typescript and compiled down to a wildly supported runtime target. The source is
    self-documenting, generating the content of a <a href="https://oooh.readme.io/docs/api-reference">ReadMe site</a>.
    Also, we ensure that the API exposed to modules never changes (only additions and deprecation are allowed), and that
    client communication is backwards and forwards compatible with all available client versions.
</p>
<p>
    The client renders a custom webview and loads a module inside an iframe. Phone and app systems are exposed by
    communicating through the API via the iframe.
</p>
<h3>Unity Bridge</h3>
<p>
    Communication from C# to JavaScript mainly occurs via passing string data evaluated as function calls. Data is passed
    from JavaScript to C# by JSON strings which are parsed to execute a C# function.
</p>
<p>
    An annotation is applied to any C# function that is eligible to be called from JavaScript. C# object instances are
    referenced via a unique ID, and ownership can be passed to JavaScript. Module context is generally short-lived, but
    when a C# object owned by JavaScript is garbage collected, it'll be destroyed in C# as well.
</p>
<p>
    To eliminate the usage of reflection, information about annotated functions is pre-compiled at build time.
    Specialized JSON parsing is performed at runtime to eliminate additional memory allocations.
</p>
<p>
    For passing large amounts of data, such as image data, microphone samples, etc... from C# to JavaScript, there's an
    alternative flow. Raw bytes are passed from C# to native code and exposed to JavaScript via a resource path. For
    example, when you connect an AudioNode or an AudioParam to a <a
        href="https://oooh.readme.io/docs/api-reference-microphoneaudionode">MicrophoneAudioNode</a>, internally it'll
    poll a file at o3h://&lt;objectId&gt; for the microphone audio samples.
</p>
<h3>Camera</h3>
<p>
    Initially, we used a third-party plugin to capture and render the device camera in Unity. However, we found the
    available plugins lacking, and created our own camera plugin.
</p>
<p>
    Our plugin is session-based, and allows multiple consumers to make concurrent requests, sharing the same captured
    texture. It also supports dual camera when available, and allows adjustment of the camera resolution.
</p>
<h3>Native Texture Composer</h3>
<p>
    Before iOS 15, a webview embedded in an app wasn't able to access the camera. Working around that limitation, we
    added a way for modules to control app texture rendering outside the webview.
</p>
<p>
    Modules are able to create a layout specifying where on the screen to render a texture source (camera feed,
    video player, or image). These textures can be rendered below the webview using Unity, in which case the module
    renders a transparent background to make the texture visible. Or the textures can be rendered natively above the
    webview, with the option to specify masks, turning areas of a rectangular texture transparent.
</p>

<h2>Content Creators</h2>
<p>
    Leaning into the capabilities of the module engine, Oooh pivoted, target content creators. Creators created content
    by playing a modules. Fans submitted to the creator's content by playing the same module, with the experience
    influenced by what the creator had done. And creators could respond to the fan's content by sending personal video
    responses.
</p>
<figure>
    <img src="Creators.webp" alt="Content Creators screenshot">
    <figcaption>Screenshots of content creation</figcaption>
</figure>
<h3>Video Editing Pipeline</h3>
<p>
    To facilitate the creation of creator videos and fan submissions, several video editing capabilities were added to
    the app. Including trimming, joining, auto highlighting, and compositing.
</p>
<p>
    Video operations are chained together as a serialized linear sequence of processing steps. This allows for the app to
    be terminated and queued video editing to continue in the next session.
</p>
<p>
    Most operations are performed using FFMpeg, but some processing intensive operations are done using the native
    functionality provided by iOS and Android. This gives a small performance improvement on iOS, but a huge improvement
    for Android where FFMpeg doesn't support hardware accelerated video editing.
</p>
<h3>Publish Pipeline</h3>
<p>
    There are many things within <i>Oooh</i> which have been called an <i>oooh</i>, but internally it's the published
    artifacts of running a module. Publishing an oooh involves uploading the output of a module run. Modules output a
    main asset<sup><a href="#1">1</a></sup> plus an optional collection of image/video/audio assets and replay data. All
    of this information, plus data associated with how to rerun the module, are uploaded to create an oooh. An oooh is
    represented on the platform as a video, with a join button. When a user joins the oooh, the module is launched again
    and given access to the assets it outputted previously. The output of that module run is again uploaded to create a
    submission to the oooh.
</p>
<p>
    The publishing pipeline is responsible for tracking all the information to upload, plus the video editing pipeline if
    the main video is edited before being posted. All publishing steps are serializable so that publishing can resume if
    the app restarts. Uploading of assets is performed via a custom native plugin that allows for uploading while the app
    is in the background.
</p>
<p>
    <sup><a id="1" href="#1">1</a></sup> The main asset was limited to being a video at this point in time. Eventually
    it could be nothing (or more commonly a sticker), and the video recorder created an image or video to post as the
    main asset.
</p>
<h3>HTML Audio Polyfill</h3>
<p>
    The webview on iOS runs as a different process, which limits some options for controlling playback. Silent switch
    behaviour, audio routing, and volume are some of the things we wanted to manage from the app. To work around this,
    we allowed modules to play audio in Unity via the o3h.js library. However, porting existing content or getting
    third-party developers to work with our api was challenging. As such, a JavaScript polyfill was created and injected
    by the o3h.js library to replace the HTML5 audio spec.
</p>
<h3>Module SDK</h3>
<div class="row">
    <div class="column">
        <p>
            Over the lifetime of Oooh there have been ~160 modules developed, with 84 of them being released. The
            majority of these were created by third-party game studios, peaking at over 10 studios working concurrently
            for Oooh. To accommodate this level of module development, an SDK app was created.
        </p>
        <p>
            The SDK was created from the same code base as the main app. Differing only by a preprocessor directive, and
            an extra scene. It presents a simplified app view that allows you to:
        </p>
        <ul>
            <li>launch a module directly</li>
            <li>configure the inputs to the module</li>
            <li>launch a module from an uri of your choosing</li>
            <li>mock app provided data</li>
            <li>review raw module outputs</li>
            <li>attach the web console from your development machine to the embedded webview</li>
        </ul>
    </div>
    <div class="column">
        <figure>
            <img src="SDK.webp" alt="SDK screenshot">
            <figcaption>Module SDK Screenshot</figcaption>
        </figure>
    </div>
</div>
<h3>Audio Ducking</h3>
<p>
    When a user plays a module to generate a submission, game music, and a video recorded by the creator, may be playing
    at the same time. While capturing microphone input audio, this creates issues with cleanly capturing the voice of the
    submitter. To combat this, a system was put into place to automatically reduce the output volume of the app when we
    detected someone talking. Afterwards, we can boost the ducked output in the final recording, as the game audio is
    captured in a different audio track.
</p>
<h3>Native Audio</h3>
<p>
    A custom plugin was developed to control audio sessions and allow microphone input data sharing.
</p>
<h3>Live Capture ML</h3>
<p>
    Machine learning models were used to perform body tracking, face tracking, and image segmentation in real time on
    either video playback or a camera feed. This information was exposed via the o3h.js library to allow modules to use
    the tracked positions in gameplay.
</p>
<p>
    Face tracking and image segmentation used a third-party SDK provided by Banuba with some local modifications to fix
    performance issues.
</p>
<p>
    Initially, body tracking used a custom tensorflow lite integration and the PoseNet model. This was later upgraded to
    use the NatML plugin with the BlazePose model. The plan was to migrate off of Banuba using other free models with
    this plugin as well.
</p>
<h3>Speech To Text</h3>
<p>
    We used speech to text capabilities provided by the mobile operating systems (iOS and Android 13+) to convert
    microphone input into a stream of text. Like most systems, this was exposed via the o3h.js library and used in
    gameplay.
</p>

<h2>Streaming</h2>
<p>
    The next pivot was to focus on creators who livestreamed, as live reacting to user submissions proved to be very
    engaging.
</p>
<figure>
    <img src="Streaming.jpg" alt="Streaming screenshot">
    <figcaption>Streaming example</figcaption>
</figure>
<h3>Screen Capture</h3>
<p>
    Allows real time capture of audio and app frame data across multiple OS windows. This uses replaykit on iOS but on
    Android, data is captured across multiple windows (native + Unity rendered) and composed into a single frame without
    any additional user permissions.
</p>
<p>
    This also supports temporarily injecting another texture into the stream, to allow for private app moments, like
    selecting an image from your camera roll.
</p>
<h3>SRT Streaming</h3>
<p>
    Due to our use of screen capture to record module gameplay, it isn't possible to use existing tools to capture the
    Oooh app in streaming software such as OBS. As an alternative, we added the ability for the Oooh app to generate
    its own srt or rtp stream and exposed it to streaming software.
</p>
<p>
    An additional benefit to this approach is that it allows us to guide non-technical users with a setup process from
    within the app. It also adds a layer of privacy in that OS notifications are not captured, and we are able to create
    sensitive areas within our app where the live content is not streamed.
</p>
<p>
    Video streaming is achieved using FFMpeg on both iOS and Android. With iOS, an additional integration of the
    HaishinKit swift library was done as it provided lower latency than FFMpeg.
</p>

<h2>Group Chat</h2>
<p>
    The final iteration of the Oooh app was a group chat experience, using ooohs as interactive elements anchoring chat
    threads.
</p>
<figure>
    <img src="GroupChat.webp" alt="Group Chat screenshot">
    <figcaption>Chat within a group</figcaption>
</figure>
<h3>Native Text Input</h3>
<p>
    Unity provides a text input field, and there are a number of third-party text input plugins, but none of them fully
    match the text input experience of using a native app. Now that our app centered around chatting, these flaws became
    quite noticeable, and we created our own plugin.
</p>
<p>
    Our text input plugin works by rendering a native text input field above Unity when a text input is focused. This
    ensures that the look and feel are 100% native regardless of your OS version or settings.
</p>
<p>
    This currently requires native rendering the entire width of the screen, not just the text input field. To meet
    design requirements, additional supported functionality is: rendering buttons beside the input field, rendering
    buttons inside the input field, animated collapse / expansion of button lists in the input field, and making the
    input field's height grow / shrink based on input size.
</p>
<h3>Photo Picker</h3>
<p>
    A modern photo picker plugin for Unity allowing for image / video selection without asking for user permissions.
</p>
<h3>AI Summary</h3>
<p>
    This is a series of suggestions available to group owners to make it easier for them to post content to their group.
</p>
<ul>
    <li>Greet new users — tracks group user list and looks for new additions that haven't been @mentioned by the group
        owner.
    </li>
    <li>Summaries new chat — consolidates all unread messages in the group and uses ChatGPT to summarize the
        conversation.
    </li>
    <li>Active threads — tracks unread message counts in threads and shows the thread with the most unread messages.</li>
    <li>Common questions — uses ChatGPT to find questions asked of the group owner and groups similar questions, allowing
        the owner to respond to them all at once.
    </li>
    <li>Suggested links — gets the topics of conversation using ChatGPT and generates news and video links for that topic
        using news service APIs.
    </li>
    <li>
        Suggested Ooohs — using the topic of conversation getting the data needed to publish selected ooohs from ChatGPT
        and allowing one click posting of an oooh.
    </li>
</ul>
<h3>Extensions</h3>
<p>
    Extensions are a container for untyped data that can be remotely updated and reflected in the app in realtime. Most
    entities (chat message, group, thread, user) in Oooh can have one or more extensions attached to them. Extensions can
    be published using the publishing pipeline and include multimedia assets.
</p>
<p>
    The goal being third party developers can write AWS lambda functions that are triggered by client actions or server
    events. These functions would create / modify extension data, and clients would reflect the changes in realtime. This
    expands on the capabilities of modules, allowing the rendered outputs to be updated without a user reopening a
    module.
</p>
<p>
    The full extension system was scheduled to launch with the next client release before Oooh shutdown. The first
    example was a poll extension. The flow being that one client would create a poll, this would call an AWS
    lambda function, which would create a comment and attach a poll extension containing the poll options. All clients in
    the group would render the comment with the poll extension to reflect that it's a poll. When another client votes on
    the poll, another AWS lambda function is called which updates the vote counts on the poll extension data. Finally, to
    complete the loop, all clients would update to show the new vote counts on the poll.
</p>
<p>
    Another example is the AI Summary feature was updated to use extensions. Mostly using server events (i.e.: someone
    joins the group, or a message is posted to the group), the same data set can be managed server side and stored in
    extension data. This allows group co-owners to share the summary data, and allows some of the computational heavy
    requests (i.e.: suggesting links / ooohs) to be preformed before the group owner loads into the group.
</p>

<h2>Other Components</h2>
<p>
    This history isn't strictly linear, and some developments don't fit in the narrative. Here are some other notable
    components used in the Oooh app.
</p>
<h3>Off Thread Native Image Decoding</h3>
<p>
    To dynamically load image data and render it in Unity, you need to use the <a
        href="https://docs.unity3d.com/ScriptReference/ImageConversion.LoadImage.html">LoadImage</a> function. This has
    performance issues in that it both decodes the image and populates the texture on the main thread. With a large image
    or several small images, frame drops are very noticeable.
</p>
<p>
    To resolve this, we developed our own decoding pipeline that runs asynchronously off the main thread. Using the image
    decoding capabilities of the underlining OS, plus libraries for some image formats with older Android versions.
</p>
<p>
    This allows us to support many more image formats, including animated formats. Animated formats can either show a
    static frame or show their animation.
</p>
<h3>UI Scaling</h3>
<p>
    To support OS settings for different text sizes, we developed a system to dynamically adjust the reference resolution
    on UI Canvas Scaler components. Generally, this "just works" as long as the anchor positions are set properly on all
    UI Rect Transforms, and it's a great way to catch issues you'd see across different resolution devices anyway.
</p>
<h3>UI Styles</h3>
<p>
    To support OS light vs. dark mode, we reduced the colours used in our app to a fixed set of named colours. Light and
    dark schemas were created mapping each colour name to a colour. Finally, a component that configured the named colour
    to use was attached alongside every Graphic component.
</p>
<p>
    The component subscribed to changes in the active mode and updated the colour of the graphic. Additionally, editor
    tools were built to allow the different modes to be tested in the scene view.
</p>
<h3>Application View Stack</h3>
<p>
    Navigation of the Oooh app is a series of view changes, each view is a prefab with a state data object. The
    application view stack controls how many view prefabs are loaded on top of each other and will destroy the prefabs to
    save memory, restoring them via their state data object when needed.
</p>

<h2>Development Tools</h2>
<p>
    Oooh has a number of components which don't have direct product impact, but which make development easier for
    developers. Here are some of the notable components.
</p>
<h3>OLogger</h3>
<p>
    A simple wrapper for Unity's debug logger that adds functionality.
</p>
<ul>
    <li>5 logging levels</li>
    <li>Conditionally compile out lower levels in release builds</li>
    <li>Configurable log level by namespace or class name, either in the editor or at runtime</li>
    <li>Options to prepend frame count or object instance id to all messages</li>
    <li>Ability to log messages from native plugins</li>
    <li>Export logs from current or previous session</li>
</ul>
<h3>Display Element UI System</h3>
<p>
    Makes the task of hooking up data to display elements generic. Separating the data source from the elements being
    rendered. This allows for common UI elements to be added or modified in a prefab without code changes.
</p>
<h3>Remote Configurable Properties</h3>
<p>
    Adding an annotation to a class property plus injection of a binder can automatically change the value of the
    property based on an override setup in firebase remote configuration. This can also be used to A/B test different
    values, as configured remotely.
</p>
<h3>Networking</h3>
<p>
    Network code is generated from webservice endpoints using OpenAPI. GraphQL schema is generated using the
    graphql-codegen/c-sharp npm package.
</p>
<p>
    Network requests are given a reactive priority, and low priority requests are queued (or all requests if there's too
    many concurrent requests) and executed when network traffic is minimal.
</p>
<p>
    It's better to make one network request for X items instead of X requests for one item. For places where it's
    difficult to pre-determine which X items to request, we have a request batching system. The batching system will
    consolidate all network requests of the same type within a frame and send a single request at the end of the frame.
</p>
<h3>Asset Validation</h3>
<p>
    To ensure there are no issues with prefabs in our project, we have an asset validation pass that runs as a unit test.
    The validation pass checks every property of every component of every prefab and scene in our project. As the object
    iteration is relatively slow (~1.5 seconds for our project), this is a pluggable framework allowing for different
    validation rules. Current validation checks are: no missing components, Graphic components are UI Styled, the Button
    component isn't used (we have a custom one), certain enum and string references are valid, object references between
    components are valid, and Unity event function targets are valid.
</p>
<h3>Reference Inspector</h3>
<p>
    Editor tool to see which components in the scene / prefab reference a given component.
</p>

<h2>Acknowledgements</h2>
<p>
    There are many, many other components in our app: emoji support, video recording, realtime chat, contacts, FTUE,
    notification, debug menus, analytics, sharing, deep linking, caching, etc... But I'm limiting the list here to the
    ones which I feel are unique / reusable / interesting.
</p>
<p>
    As much as I'd like to claim, I built all of this myself, it couldn't have been done without an exceptional
    engineering team.
</p>
<ul>
    <li><a href="https://www.linkedin.com/in/jamesmaxwellhall/">James Hall</a> — Lead Senior Engineer</li>
    <li><a href="https://www.linkedin.com/in/tylervenables/">Tyler Venables</a> — Senior Engineer</li>
    <li><a href="https://www.linkedin.com/in/simon-roscoe/">Simon Roscoe</a> — Lead Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/danielle-tilley">Danielle Tilley</a> — Lead Senior Engineer</li>
    <li><a href="https://www.linkedin.com/in/matt-delorme-47b1a4172/">Matt Delorme</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/rogerbraunstein/">Roger Braunstein</a> — Principal Software engineer</li>
    <li><a href="https://www.linkedin.com/in/josephdasilva24">Joseph Da Silva</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/dylllllan/">Dylan Aujla</a> — Software Engineer</li>
    <li><a href=https://www.linkedin.com/in/christopher-adamson/">Chris Adamson</a> — Lead Senior Engineer</li>
    <li><a href="https://www.linkedin.com/in/dalavender/">Dan Lavender</a> — Director of Engineering</li>
    <li><a href="https://www.linkedin.com/in/paulo-rizkalla-189a077/">Paulo Rizkalla</a> — Director of Engineering</li>
    <li><a href="https://www.linkedin.com/in/zack-dupont/">Zack Dupont</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/comet-li-3188b5140/">Comet Li</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/roylovejoy-codepoet/">Roy Lovejoy</a> — Principal Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/russ-horton-a109771a/"> Russ Horton</a> — Lead Game Designer</li>
    <li><a href="https://www.linkedin.com/in/kyall-barrows-6665454/">Kyall Barrows</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/isabella-fawcett-jones/">Isabella Fawcett-Jones</a> — Software Engineer</li>
    <li><a href="https://www.linkedin.com/in/mason-macklem-b45b662b/"> Mason Macklem</a> — Senior Researcher</li>


</ul>
<p>
    I'd also like to call out <a href="https://www.linkedin.com/in/derekhilder/">Derek Hilder</a>, my counterpoint on
    server development, who's put together an excellent reference of the <a href="https://dbhilder.github.io/oooh/">Oooh
    backend architecture</a>.
</p>
</body>
</html>
